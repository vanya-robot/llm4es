{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlMD1ISVzzsR",
        "outputId": "38391991-bde9-4124-df9b-23ebce3ebcc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llm4es'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 51 (delta 16), reused 45 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (51/51), 27.41 KiB | 483.00 KiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vanya-robot/llm4es.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m llm4es.scripts.run_pipeline \\\n",
        "  --gpu \\\n",
        "  --use-llm \\\n",
        "  --serialization_mode mixed \\\n",
        "  --llm_model Qwen/Qwen2.5-0.5B-Instruct \\\n",
        "  --max_users 10 \\\n",
        "  --enrich_variants 1 \\\n",
        "  --max_new_tokens 256 \\\n",
        "  --finetune dry_run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtDxzxt21T0C",
        "outputId": "c4d89fd7-98c3-4093-f9cb-e8213b26e62e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2026-02-23 05:47:44] INFO - ============================================================\n",
            "[2026-02-23 05:47:44] INFO - LLM4ES Pipeline\n",
            "[2026-02-23 05:47:44] INFO - ============================================================\n",
            "[2026-02-23 05:47:44] INFO - [DEVICE] cuda (Tesla T4)\n",
            "[2026-02-23 05:47:44] INFO - [DEVICE] cuda\n",
            "[2026-02-23 05:47:44] INFO - [MODE] serialization_mode=mixed\n",
            "[2026-02-23 05:47:44] INFO - [ENRICH] LLM (model=Qwen/Qwen2.5-0.5B-Instruct, variants=1, max_new_tokens=256)\n",
            "[2026-02-23 05:47:44] INFO - [MODEL] Qwen/Qwen2.5-0.5B-Instruct\n",
            "[2026-02-23 05:47:44] INFO - Starting: Stage 1: Download\n",
            "[2026-02-23 05:47:44] INFO - Downloading MovieLens-100K from https://files.grouplens.org/datasets/movielens/ml-100k.zip ...\n",
            "[2026-02-23 05:47:46] INFO - Downloaded to data/raw/ml-100k.zip\n",
            "[2026-02-23 05:47:46] INFO - Extracting archive ...\n",
            "[2026-02-23 05:47:46] INFO - Extracted to data/raw/ml-100k\n",
            "[2026-02-23 05:47:46] INFO - Finished: Stage 1: Download (1.91s)\n",
            "[2026-02-23 05:47:46] INFO - Starting: Stage 2: Preprocess\n",
            "[2026-02-23 05:47:49] INFO - Preprocessed: 10 users, avg 44.6 events/user\n",
            "[2026-02-23 05:47:49] INFO - Finished: Stage 2: Preprocess (2.98s)\n",
            "[2026-02-23 05:47:49] INFO - Users: 10, events example: 50\n",
            "[2026-02-23 05:47:49] INFO - Starting: Stage 3: Serialize\n",
            "[2026-02-23 05:47:49] INFO - Finished: Stage 3: Serialize (0.01s)\n",
            "[2026-02-23 05:47:49] INFO - Text example (user 1, first 200 chars):\n",
            "[2026-02-23 05:47:49] INFO - Title | Year | Genres | Rating | Date\n",
            "Monty Python and the Holy Grail | 1974 | Comedy | excellent | 1997-09-22\n",
            "Empire Strikes Back, The | 1980 | Action, Adventure, Drama, Romance, Science Fiction, War...\n",
            "[2026-02-23 05:47:49] INFO - Starting: Stage 4: Build texts\n",
            "[2026-02-23 05:47:49] INFO - Loading instruct LLM 'Qwen/Qwen2.5-0.5B-Instruct' on cuda ...\n",
            "config.json: 100% 659/659 [00:00<00:00, 3.34MB/s]\n",
            "tokenizer_config.json: 7.30kB [00:00, 19.2MB/s]\n",
            "vocab.json: 2.78MB [00:00, 65.4MB/s]\n",
            "merges.txt: 1.67MB [00:00, 80.1MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 107MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "model.safetensors: 100% 988M/988M [00:07<00:00, 141MB/s]\n",
            "Loading weights: 100% 290/290 [00:00<00:00, 345.26it/s, Materializing param=model.norm.weight]\n",
            "generation_config.json: 100% 242/242 [00:00<00:00, 1.70MB/s]\n",
            "[2026-02-23 05:48:00] INFO - Instruct LLM loaded: 494.0M params, dtype=torch.float16\n",
            "LLM enrichment: 100% 10/10 [01:18<00:00,  7.88s/it]\n",
            "[2026-02-23 05:49:19] INFO - LLM enrichment done: 10 users, 0 cache hits, 10 generated\n",
            "[2026-02-23 05:49:19] INFO - Freed enrichment model memory\n",
            "[2026-02-23 05:49:19] INFO - Finished: Stage 4: Build texts (90.60s)\n",
            "[2026-02-23 05:49:19] INFO - Total texts: 20 (10 users, ~2.0 texts/user)\n",
            "[2026-02-23 05:49:19] INFO - Starting: Stage 5: Load model\n",
            "[2026-02-23 05:49:19] INFO - Loading model 'Qwen/Qwen2.5-0.5B-Instruct' on cuda ...\n",
            "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Loading weights: 100% 290/290 [00:00<00:00, 393.47it/s, Materializing param=model.norm.weight]\n",
            "[2026-02-23 05:49:22] INFO - Model loaded: 494.0M params, 24 layers, hidden_size=896, dtype=torch.float16\n",
            "[2026-02-23 05:49:22] INFO - Finished: Stage 5: Load model (2.91s)\n",
            "[2026-02-23 05:49:22] INFO - RSS memory: 3048.5 MB\n",
            "[2026-02-23 05:49:22] INFO - Text stats: 20 texts, avg 1802 chars, avg 366 tokens\n",
            "[2026-02-23 05:49:22] INFO - Starting: Stage 5b: Fine-tune (mode=dry_run)\n",
            "[2026-02-23 05:49:22] INFO - Fine-tuning mode = 'dry_run': 2 steps\n",
            "[2026-02-23 05:49:22] INFO - Fine-tune config: device=cuda, grad_accum=8, batch_size=2, effective_batch=16\n",
            "[2026-02-23 05:49:22] INFO - Gradient checkpointing enabled (saves VRAM)\n",
            "[2026-02-23 05:49:22] INFO - Starting fine-tuning: 2 optimizer steps, batch_size=2, lr=5e-05\n",
            "[2026-02-23 05:49:22] INFO - RSS memory: 3048.5 MB\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "[2026-02-23 05:49:33] INFO -   Step 1/2 | loss=5.5631 | time=1.59s\n",
            "[2026-02-23 05:49:35] INFO -   Step 2/2 | loss=0.1257 | time=1.46s\n",
            "[2026-02-23 05:49:35] INFO - Fine-tuning complete. Average loss: 2.8444\n",
            "[2026-02-23 05:49:35] INFO - RSS memory: 3110.6 MB\n",
            "[2026-02-23 05:49:35] INFO - Checkpoint saving disabled (--save_ckpt to enable). Would save to: artifacts/checkpoints/\n",
            "[2026-02-23 05:49:35] INFO - Finished: Stage 5b: Fine-tune (mode=dry_run) (12.46s)\n",
            "[2026-02-23 05:49:35] INFO - Starting: Stage 6: Extract embeddings\n",
            "[2026-02-23 05:49:35] INFO - Extracting embeddings: 20 texts, 24 transformer layers, k=8, batch_size=4, device=cuda\n",
            "[2026-02-23 05:49:35] INFO -   hidden_states: 25 (1 emb + 24 transformer)\n",
            "[2026-02-23 05:49:35] INFO -   layer shape: [4, 512, 896], k_used: 8\n",
            "[2026-02-23 05:49:36] INFO - Embeddings shape: (20, 896)\n",
            "[2026-02-23 05:49:36] INFO - Token stats: avg input_ids=512.0, avg real tokens=366.0\n",
            "[2026-02-23 05:49:36] INFO - Finished: Stage 6: Extract embeddings (1.16s)\n",
            "[2026-02-23 05:49:36] INFO - All embeddings shape: (20, 896)\n",
            "[2026-02-23 05:49:36] INFO - Starting: Stage 6b: Average per user\n",
            "[2026-02-23 05:49:36] INFO - Finished: Stage 6b: Average per user (0.00s)\n",
            "[2026-02-23 05:49:36] INFO - User embedding matrix: (10, 896)\n",
            "[2026-02-23 05:49:36] INFO - Cosine similarity: mean=0.9847, max=0.9950\n",
            "[2026-02-23 05:49:36] WARNING - Embeddings highly similar (mean cosine > 0.95). Check truncation or max_length.\n",
            "[2026-02-23 05:49:36] INFO - Starting: Stage 7: Downstream classification\n",
            "[2026-02-23 05:49:36] INFO - Downstream task 'gender': 10 samples, classes=['F', 'M'], distribution=[2, 8]\n",
            "[2026-02-23 05:49:36] INFO - Train size: 8, distribution: {'F': 2, 'M': 6}\n",
            "[2026-02-23 05:49:36] INFO - Test size:  2, distribution: {'F': 0, 'M': 2}\n",
            "[2026-02-23 05:49:36] INFO - Accuracy: 1.0000\n",
            "[2026-02-23 05:49:36] WARNING - Test set has only one class, ROC-AUC undefined.\n",
            "[2026-02-23 05:49:36] INFO - Confusion Matrix:\n",
            "[[0 0]\n",
            " [0 2]]\n",
            "[2026-02-23 05:49:36] INFO - Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.00      0.00      0.00         0\n",
            "           M       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       0.50      0.50      0.50         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "[2026-02-23 05:49:36] INFO - Finished: Stage 7: Downstream classification (0.06s)\n",
            "[2026-02-23 05:49:36] INFO - \n",
            "[2026-02-23 05:49:36] INFO - ============================================================\n",
            "[2026-02-23 05:49:36] INFO - PIPELINE REPORT\n",
            "[2026-02-23 05:49:36] INFO - ============================================================\n",
            "[2026-02-23 05:49:36] INFO - Device:             cuda\n",
            "[2026-02-23 05:49:36] INFO - Model:              Qwen/Qwen2.5-0.5B-Instruct\n",
            "[2026-02-23 05:49:36] INFO - Users:              10\n",
            "[2026-02-23 05:49:36] INFO - Serialization mode: mixed\n",
            "[2026-02-23 05:49:36] INFO - Enrichment:         LLM (Qwen/Qwen2.5-0.5B-Instruct)\n",
            "[2026-02-23 05:49:36] INFO - Texts per user:     2.0\n",
            "[2026-02-23 05:49:36] INFO - Avg text length:    1802 chars / 366 tokens\n",
            "[2026-02-23 05:49:36] INFO - Embedding dim:      896\n",
            "[2026-02-23 05:49:36] INFO - Transformer layers: 24\n",
            "[2026-02-23 05:49:36] INFO - k (last layers):    8\n",
            "[2026-02-23 05:49:36] INFO - Fine-tune mode:     dry_run\n",
            "[2026-02-23 05:49:36] INFO - Task:               gender\n",
            "[2026-02-23 05:49:36] INFO - Accuracy:           1.0\n",
            "[2026-02-23 05:49:36] INFO - ROC-AUC:            N/A\n",
            "[2026-02-23 05:49:36] INFO - \n",
            "[2026-02-23 05:49:36] INFO - Timings:\n",
            "[2026-02-23 05:49:36] INFO -   download            : 1.91s\n",
            "[2026-02-23 05:49:36] INFO -   preprocess          : 2.98s\n",
            "[2026-02-23 05:49:36] INFO -   serialize           : 0.01s\n",
            "[2026-02-23 05:49:36] INFO -   build_texts         : 90.60s\n",
            "[2026-02-23 05:49:36] INFO -   load_model          : 2.91s\n",
            "[2026-02-23 05:49:36] INFO -   finetune            : 12.46s\n",
            "[2026-02-23 05:49:36] INFO -   embed               : 1.16s\n",
            "[2026-02-23 05:49:36] INFO -   avg_embeddings      : 0.00s\n",
            "[2026-02-23 05:49:36] INFO -   downstream          : 0.06s\n",
            "[2026-02-23 05:49:36] INFO -   total               : 112.11s\n",
            "[2026-02-23 05:49:36] INFO - ============================================================\n",
            "[2026-02-23 05:49:36] INFO - RSS memory: 3116.6 MB\n"
          ]
        }
      ]
    }
  ]
}